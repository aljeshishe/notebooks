{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg_gpu_v2_with_wb_graph_samples_count_dependance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aljeshishe/notebooks/blob/master/vgg_gpu_v2_with_wb_graph_samples_count_dependance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYN4BJRj04iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import sys \n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from time import time "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKmeruBkZna8",
        "colab_type": "code",
        "outputId": "3e652765-924d-4ef0-b1b1-87ab3cd6eb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "import os\n",
        "# use gpu/cpu/tpu\n",
        "# see details in https://colab.research.google.com/drive/1cpuwjKTJbMjlvZ7opyrWzMXF_NYnjkiE#scrollTo=y3gk7nSvTUFZ\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "COLAB_TPU_ADDR = os.environ.get('COLAB_TPU_ADDR')\n",
        "if COLAB_TPU_ADDR:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + COLAB_TPU_ADDR)\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  # This is the TPU initialization code that has to be at the beginning.\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "  print('Running on TPU ')  \n",
        "elif len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on single GPU  /physical_device:GPU:0\n",
            "Number of accelerators:  1\n",
            "Mon May  4 11:38:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypW8-j30ulfo",
        "colab_type": "code",
        "outputId": "39e9ef77-87ab-43db-8bcc-71ccc4601102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def notebook_name():\n",
        "  import re\n",
        "  import ipykernel\n",
        "  import requests\n",
        "\n",
        "  from notebook.notebookapp import list_running_servers\n",
        "  # kernel_id = re.search('kernel-(.*).json', ipykernel.connect.get_connection_file()).group(1)\n",
        "  for ss in list_running_servers():\n",
        "      response = requests.get(f'{ss[\"url\"]}api/sessions',params={'token': ss.get('token', '')})\n",
        "      return response.json()[0]['name']\n",
        "\n",
        "\n",
        "project, _, _ = notebook_name().rpartition('.')\n",
        "\n",
        "import re \n",
        "project = re.sub('[^-a-zA-Z0-9_]+', '_', project)\n",
        "\n",
        "working_dir = f'/content/drive/My Drive/Colab Notebooks/{project}'\n",
        "print(f'Current project: {project}')\n",
        "print(f'Places at: {working_dir}')\n",
        "\n",
        "import pathlib\n",
        "pathlib.Path(working_dir).mkdir(parents=True, exist_ok=True)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Current project: vgg_gpu_v2_with_wb_graph_samples_count_dependance\n",
            "Places at: /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJZjYfD0_rFO",
        "colab_type": "code",
        "outputId": "765e40b0-7f60-40ae-d33b-eeb852191fa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "labels = [\n",
        "    'airplane', \n",
        "    'automobile',\n",
        "    'bird',\n",
        "    'cat',\n",
        "    'deer',\n",
        "    'dog',\n",
        "    'frog',\n",
        "    'horse',\n",
        "    'ship',\n",
        "    'truck'\n",
        "]\n",
        "\n",
        "#load dataset\n",
        "(trainX, trainY),(testX, testY) = cifar10.load_data()\n",
        "\n",
        "#one hot encode the target \n",
        "trainY = keras.utils.to_categorical(trainY)\n",
        "testY = keras.utils.to_categorical(testY)\n",
        "\n",
        "# normalize the data\n",
        "trainX = trainX.astype('float32') / 255.0\n",
        "testX = testX.astype('float32') / 255.0\n",
        "\n",
        "v_split = 0.5\n",
        "index_of_validation = int(v_split * len(testX))\n",
        "validX = np.asarray(testX[-index_of_validation:])\n",
        "validY = np.asarray(testY[-index_of_validation:])\n",
        "testX = np.asarray(testX[:-index_of_validation])\n",
        "testY = np.asarray(testY[:-index_of_validation])\n",
        "\n",
        "print(f'Prepared dataset:')\n",
        "print(f'trainX:{trainX.shape}')\n",
        "print(f'trainY:{trainY.shape}')\n",
        "print(f'validX:{validX.shape}')\n",
        "print(f'validY:{validY.shape}')\n",
        "print(f'testX:{testX.shape}')\n",
        "print(f'testY:{testY.shape}')\n",
        "print(f'labels:{\" \".join(labels)}')\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 3s 0us/step\n",
            "Prepared dataset:\n",
            "trainX:(50000, 32, 32, 3)\n",
            "trainY:(50000, 10)\n",
            "validX:(5000, 32, 32, 3)\n",
            "validY:(5000, 10)\n",
            "testX:(5000, 32, 32, 3)\n",
            "testY:(5000, 10)\n",
            "labels:airplane automobile bird cat deer dog frog horse ship truck\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYxyiIGoPQ3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "def baseline():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32,32,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(128,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.4))\n",
        "   \n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation = 'softmax'))\n",
        "    \n",
        "    #compile model \n",
        "    opt = SGD(lr = config.lr, momentum=config.momentum)\n",
        "    model.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd1xlEhUAXDB",
        "colab_type": "code",
        "outputId": "46781bec-ee4e-4d91-8ced-2f35b44b78d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "results = []\n",
        "results_count = []\n",
        "steps = 10\n",
        "for step in range(1, steps+1):\n",
        "  config = dict(\n",
        "    batch_size = 64,          # input batch size for training (default: 64)\n",
        "    epochs = 5,             # number of epochs to train (default: 10)\n",
        "    lr = 0.001,               # learning rate (default: 0.01)\n",
        "    momentum = 0.9,          # SGD momentum (default: 0.5) \n",
        "    seed = 42,               # random seed (default: 42)\n",
        "    log_interval = 10,     # how many batches to wait before logging training status\n",
        "    weight_decay = 0.0005\n",
        "  )\n",
        "  wandb.init(project=project, dir=working_dir, config=config)\n",
        "  config = wandb.config\n",
        "  with strategy.scope():\n",
        "    model = baseline()\n",
        "  count = int(len(trainX)/steps * step)\n",
        "  part_x = trainX[:count]\n",
        "  part_y = trainY[:count]\n",
        "  steps_per_epoch = int(len(trainX) / config.batch_size)\n",
        "  print(f'step={step} count={count} steps_per_epoch={steps_per_epoch}')\n",
        "  h = model.fit(x=part_x, \n",
        "            y=part_y, \n",
        "            batch_size=config.batch_size,\n",
        "            initial_epoch=0,\n",
        "            epochs=config.epochs,\n",
        "            validation_data=(validX, validY), verbose=0,\n",
        "            callbacks=[WandbCallback(data_type=\"image\",\n",
        "                                      validation_data=(validX, validY),\n",
        "                                      labels=labels,\n",
        "                                      predictions=10,\n",
        "                                      save_model=True,\n",
        "                                      verbose=1)])\n",
        "\n",
        "  results.append(h.history)\n",
        "  results_count.append(count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/3ielpb0q\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/3ielpb0q</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "step=1 count=5000 steps_per_epoch=781\n",
            "Epoch 00000: val_loss improved from inf to 2.39470, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114122-3ielpb0q/model-best.h5\n",
            "Epoch 00003: val_loss improved from 2.39470 to 2.12591, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114122-3ielpb0q/model-best.h5\n",
            "Epoch 00004: val_loss improved from 2.12591 to 1.97124, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114122-3ielpb0q/model-best.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/2cgubt96\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/2cgubt96</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "step=2 count=10000 steps_per_epoch=781\n",
            "Epoch 00000: val_loss improved from inf to 2.51064, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114137-2cgubt96/model-best.h5\n",
            "Epoch 00001: val_loss improved from 2.51064 to 1.90947, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114137-2cgubt96/model-best.h5\n",
            "Epoch 00002: val_loss improved from 1.90947 to 1.60591, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114137-2cgubt96/model-best.h5\n",
            "Epoch 00003: val_loss improved from 1.60591 to 1.52734, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114137-2cgubt96/model-best.h5\n",
            "Epoch 00004: val_loss improved from 1.52734 to 1.46337, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114137-2cgubt96/model-best.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/1z4wji1l\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/1z4wji1l</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "step=3 count=15000 steps_per_epoch=781\n",
            "Epoch 00000: val_loss improved from inf to 2.27711, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114150-1z4wji1l/model-best.h5\n",
            "Epoch 00001: val_loss improved from 2.27711 to 1.63978, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114150-1z4wji1l/model-best.h5\n",
            "Epoch 00002: val_loss improved from 1.63978 to 1.59692, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114150-1z4wji1l/model-best.h5\n",
            "Epoch 00003: val_loss improved from 1.59692 to 1.50584, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114150-1z4wji1l/model-best.h5\n",
            "Epoch 00004: val_loss improved from 1.50584 to 1.45699, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114150-1z4wji1l/model-best.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/369n1ue6\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/369n1ue6</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "step=4 count=20000 steps_per_epoch=781\n",
            "Epoch 00000: val_loss improved from inf to 2.14219, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114205-369n1ue6/model-best.h5\n",
            "Epoch 00001: val_loss improved from 2.14219 to 1.56794, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114205-369n1ue6/model-best.h5\n",
            "Epoch 00003: val_loss improved from 1.56794 to 1.45504, saving model to /content/drive/My Drive/Colab Notebooks/vgg_gpu_v2_with_wb_graph_samples_count_dependance/wandb/run-20200504_114205-369n1ue6/model-best.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/1t4899pu\" target=\"_blank\">https://app.wandb.ai/grachev/vgg_gpu_v2_with_wb_graph_samples_count_dependance/runs/1t4899pu</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiWLooCkeWJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_acc = [(i, result['val_accuracy'][-1]) for i, result in zip(results_count, results)]\n",
        "acc = [(i, result['accuracy'][-1]) for i, result in zip(results_count, results)]\n",
        "val_loss = [(i, result['val_loss'][-1]) for i, result in zip(results_count, results)]\n",
        "loss = [(i, result['loss'][-1]) for i, result in zip(results_count, results)]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(*zip(*val_acc))\n",
        "plt.plot(*zip(*acc))\n",
        "plt.plot(*zip(*val_loss))\n",
        "plt.plot(*zip(*loss))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}