{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aljeshishe/notebooks/blob/master/How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw0IQ_d4hmRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install kaggle -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFaVpK0pjQHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {'username':'aljeshishe','key':'32deca82aa1c29fbaeadcce2bf470af4'}\n",
        "with open('kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXCybSxhjWYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19a7f5a6-6642-4370-caa6-bb34741d2bb6"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX5DGgCei97M",
        "colab_type": "code",
        "outputId": "9ab2689b-d323-4d57-9cf3-ce7efa318131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "sampleSubmission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test1.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjzLLVjerCAa",
        "colab_type": "code",
        "outputId": "c92eeef6-3cbe-4551-f722-12f978874583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!unzip test1.zip > /dev/null\n",
        "!unzip train.zip > /dev/null"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace test1/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: replace train/cat.0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKmeruBkZna8",
        "colab_type": "code",
        "outputId": "4893375b-4407-47d6-a132-ef91e656ed05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on single GPU  /physical_device:GPU:0\n",
            "Number of accelerators:  1\n",
            "Mon May 11 08:12:08 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    28W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypW8-j30ulfo",
        "colab_type": "code",
        "outputId": "e1a9fc11-d0a0-4d28-b026-fb03f2acca8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def notebook_name():\n",
        "  import re\n",
        "  import ipykernel\n",
        "  import requests\n",
        "\n",
        "  from notebook.notebookapp import list_running_servers\n",
        "  # kernel_id = re.search('kernel-(.*).json', ipykernel.connect.get_connection_file()).group(1)\n",
        "  for ss in list_running_servers():\n",
        "      response = requests.get(f'{ss[\"url\"]}api/sessions',params={'token': ss.get('token', '')})\n",
        "      return response.json()[0]['name']\n",
        "\n",
        "\n",
        "project, _, _ = notebook_name().rpartition('.')\n",
        "\n",
        "import re \n",
        "project = re.sub('[^-a-zA-Z0-9_]+', '_', project)\n",
        "\n",
        "working_dir = f'/content/drive/My Drive/Colab Notebooks/{project}'\n",
        "print(f'Current project: {project}')\n",
        "print(f'Places at: {working_dir}')\n",
        "\n",
        "import pathlib\n",
        "pathlib.Path(working_dir).mkdir(parents=True, exist_ok=True)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current project: Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\n",
            "Places at: /content/drive/My Drive/Colab Notebooks/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5OT5F7-lNbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHWvGmF0lWpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install image-classifiers -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETJPnoBGqyNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import os\n",
        "\n",
        "train_dir = 'train/'\n",
        "test_dir = 'test1/'\n",
        "filenames = os.listdir(train_dir)\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories.append(\"1\")\n",
        "    else:\n",
        "        categories.append(\"0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRpiXPg1lDQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import InceptionResNetV2\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "from classification_models.keras import Classifiers\n",
        "\n",
        "\n",
        "\n",
        "def run():\n",
        "    config = dict(\n",
        "      batch_size=64,\n",
        "      epochs=10,\n",
        "      lr=1e-4,\n",
        "      momentum=0.9,\n",
        "      steps_per_epoch=20000/64,\n",
        "      model_name=\"vgg16\",\n",
        "      samples=10)\n",
        "\n",
        "    run = wandb.init(dir=working_dir, config=config)\n",
        "    conf = run.config\n",
        "    print(conf)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'filename': filenames,\n",
        "        'category': categories\n",
        "    })\n",
        "    df.head()\n",
        "\n",
        "    image_size = 224\n",
        "    input_shape = (image_size, image_size, 3)\n",
        "\n",
        "    epochs = conf.epochs\n",
        "    batch_size = conf.batch_size\n",
        "\n",
        "    ModelClass, preprocess_input = Classifiers.get(conf.model_name)\n",
        "    pre_trained_model = ModelClass(input_shape=input_shape, include_top=False, weights=\"imagenet\")\n",
        "    # pre_trained_model.summary()\n",
        "\n",
        "    for layer in pre_trained_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # for layer in pre_trained_model.layers:\n",
        "    #     layer.trainable = True\n",
        "\n",
        "    last_layer = pre_trained_model.layers[-1]\n",
        "    last_output = last_layer.output\n",
        "\n",
        "    x = GlobalMaxPooling2D()(last_output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(pre_trained_model.input, x)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=optimizers.SGD(lr=conf.lr, momentum=conf.momentum),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    train_df, validate_df = train_test_split(df, test_size=0.1)\n",
        "    train_df = train_df.reset_index()\n",
        "    validate_df = validate_df.reset_index()\n",
        "\n",
        "    validate_df = validate_df.sample(n=2000).reset_index() # use for fast testing code purpose\n",
        "    train_df = train_df.sample(n=conf.samples).reset_index() # use for fast testing code purpose\n",
        "\n",
        "    total_train = train_df.shape[0]\n",
        "    total_validate = validate_df.shape[0]\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=15,\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest',\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df, \n",
        "        train_dir, \n",
        "        x_col='filename',\n",
        "        y_col='category',\n",
        "        class_mode='binary',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    validation_generator = validation_datagen.flow_from_dataframe(\n",
        "        validate_df, \n",
        "        train_dir, \n",
        "        x_col='filename',\n",
        "        y_col='category',\n",
        "        class_mode='binary',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # fine-tune the model\n",
        "    history = model.fit_generator(\n",
        "        train_generator,\n",
        "        epochs=conf.epochs,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=total_validate//conf.batch_size,\n",
        "        steps_per_epoch=conf.steps_per_epoch,\n",
        "        verbose=1,\n",
        "        callbacks=[WandbCallback(save_model=True, verbose=1)])\n",
        "        #keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "    return history\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wghXao61mHwg",
        "colab_type": "code",
        "outputId": "88734c02-0d44-4eac-df0b-1070da88d88d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true
      },
      "source": [
        "\n",
        "!WANDB_API_KEY=723983b2d42ccd7c5510bbeb0549aa73f1242844\n",
        "!export WANDB_API_KEY\n",
        "\n",
        "import wandb\n",
        "sweep_config = {\n",
        "  \"name\": \"My Sweep\",\n",
        "  \"method\": \"grid\",\n",
        "  \"parameters\": {\n",
        "        \"samples\": {\n",
        "            \"values\": [10, 50, 100, 1000, 20000]\n",
        "        },\n",
        "        \"model_name\": {\n",
        "            \"values\": [\"vgg16\", \"resnext101\", \"inceptionresnetv2\", \"nasnetlarge\"]\n",
        "        }\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=project)\n",
        "wandb.agent(sweep_id, function=run)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: djxmo76x\n",
            "Sweep URL: https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x\n",
            "wandb: Agent Starting Run: vrfqg2i0 with config:\n",
            "\tmodel_name: vgg16\n",
            "\tsamples: 10\n",
            "wandb: Agent Started Run: vrfqg2i0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/vrfqg2i0\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/vrfqg2i0</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: keras\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 64\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 10\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.0001\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: vgg16\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "samples:\n",
            "  desc: null\n",
            "  value: 10\n",
            "steps_per_epoch:\n",
            "  desc: null\n",
            "  value: 312.5\n",
            "\n",
            "Found 10 validated image filenames belonging to 2 classes.\n",
            "Found 2000 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "313/312 [==============================] - 72s 232ms/step - loss: 0.3952 - accuracy: 0.8313 - val_loss: 0.5397 - val_accuracy: 0.6048\n",
            "Epoch 00000: val_loss improved from inf to 0.53965, saving model to /content/wandb/run-20200511_084419-vrfqg2i0/model-best.h5\n",
            "Epoch 2/10\n",
            "313/312 [==============================] - 70s 225ms/step - loss: 0.1728 - accuracy: 0.9645 - val_loss: 0.5585 - val_accuracy: 0.6420\n",
            "Epoch 3/10\n",
            "313/312 [==============================] - 70s 223ms/step - loss: 0.1110 - accuracy: 0.9866 - val_loss: 0.7018 - val_accuracy: 0.6446\n",
            "Epoch 4/10\n",
            "313/312 [==============================] - 70s 223ms/step - loss: 0.0779 - accuracy: 0.9958 - val_loss: 0.7769 - val_accuracy: 0.6482\n",
            "Epoch 5/10\n",
            "313/312 [==============================] - 70s 223ms/step - loss: 0.0607 - accuracy: 0.9965 - val_loss: 0.6449 - val_accuracy: 0.6472\n",
            "Epoch 6/10\n",
            "313/312 [==============================] - 70s 223ms/step - loss: 0.0482 - accuracy: 0.9987 - val_loss: 0.7992 - val_accuracy: 0.6550\n",
            "Epoch 7/10\n",
            "313/312 [==============================] - 70s 224ms/step - loss: 0.0395 - accuracy: 0.9994 - val_loss: 0.6065 - val_accuracy: 0.6772\n",
            "Epoch 8/10\n",
            "313/312 [==============================] - 70s 224ms/step - loss: 0.0341 - accuracy: 0.9990 - val_loss: 0.8264 - val_accuracy: 0.6643\n",
            "Epoch 9/10\n",
            "313/312 [==============================] - 70s 224ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.6736 - val_accuracy: 0.6705\n",
            "Epoch 10/10\n",
            "313/312 [==============================] - 70s 224ms/step - loss: 0.0261 - accuracy: 0.9997 - val_loss: 0.5359 - val_accuracy: 0.6596\n",
            "Epoch 00009: val_loss improved from 0.53965 to 0.53592, saving model to /content/wandb/run-20200511_084419-vrfqg2i0/model-best.h5\n",
            "wandb: Agent Finished Run: vrfqg2i0 \n",
            "\n",
            "wandb: Agent Starting Run: pmxcobwm with config:\n",
            "\tmodel_name: vgg16\n",
            "\tsamples: 50\n",
            "wandb: Agent Started Run: pmxcobwm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/pmxcobwm\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/pmxcobwm</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: keras\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 64\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 10\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.0001\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: vgg16\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "samples:\n",
            "  desc: null\n",
            "  value: 50\n",
            "steps_per_epoch:\n",
            "  desc: null\n",
            "  value: 312.5\n",
            "\n",
            "Found 50 validated image filenames belonging to 2 classes.\n",
            "Found 2000 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "313/312 [==============================] - 237s 758ms/step - loss: 0.6599 - accuracy: 0.6298 - val_loss: 0.6455 - val_accuracy: 0.7213\n",
            "Epoch 00000: val_loss improved from inf to 0.64547, saving model to /content/wandb/run-20200511_085614-pmxcobwm/model-best.h5\n",
            "Epoch 2/10\n",
            "270/312 [========================>.....] - ETA: 30s - loss: 0.5055 - accuracy: 0.7581"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:18.927409, resuming normal operation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "282/312 [==========================>...] - ETA: 22s - loss: 0.5035 - accuracy: 0.7598"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "500 response executing GraphQL.\n",
            "{\"error\":\"Error 1040: Too many connections\"}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "301/312 [===========================>..] - ETA: 8s - loss: 0.5017 - accuracy: 0.7608"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "500 response executing GraphQL.\n",
            "{\"error\":\"Error 1040: Too many connections\"}\n",
            "\n",
            "Retry attempt failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/wandb/retry.py\", line 95, in __call__\n",
            "    result = self._call_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/wandb/apis/internal.py\", line 116, in execute\n",
            "    six.reraise(*sys.exc_info())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/wandb/apis/internal.py\", line 110, in execute\n",
            "    return self.client.execute(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gql/client.py\", line 52, in execute\n",
            "    result = self._get_result(document, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gql/client.py\", line 60, in _get_result\n",
            "    return self.transport.execute(document, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gql/transport/requests.py\", line 39, in execute\n",
            "    request.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/models.py\", line 941, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/graphql\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (HTTPError), entering retry loop. See /content/wandb/debug.log for full traceback.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "307/312 [============================>.] - ETA: 3s - loss: 0.5011 - accuracy: 0.7610"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "500 response executing GraphQL.\n",
            "{\"error\":\"Error 1040: Too many connections\"}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "312/312 [============================>.] - ETA: 0s - loss: 0.5002 - accuracy: 0.7617"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/pmxcobwm/file_stream. args: ('https://api.wandb.ai/files/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/pmxcobwm/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 38, 'content': ['2020-05-11T09:03:21.067519 257/312 [=======================>......] - ETA: 40s - loss: 0.5086 - accuracy: 0.7549\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\r']}, 'wandb-events.jsonl': {'offset': 13, 'content': ['{\"system.gpu.0.gpu\": 18.2, \"system.gpu.0.memory\": 9.6, \"system.gpu.0.memoryAllocated\": 55.25, \"system.gpu.0.temp\": 72.53, \"system.gpu.0.powerWatts\": 90.17, \"system.gpu.0.powerPercent\": 36.07, \"system.cpu\": 52.93, \"system.memory\": 17.8, \"system.disk\": 52.1, \"system.proc.memory.availableMB\": 10707.54, \"system.proc.memory.rssMB\": 2725.42, \"system.proc.memory.percent\": 20.93, \"system.proc.cpu.threads\": 36.53, \"system.network.sent\": 64683729, \"system.network.recv\": 3622609, \"_wandb\": true, \"_timestamp\": 1589187796, \"_runtime\": 2495}\\n']}}}}\n",
            "500 response executing GraphQL.\n",
            "{\"errors\":[{\"message\":\"Error 1040: Too many connections\",\"path\":[\"agentHeartbeat\"]}],\"data\":{\"agentHeartbeat\":null}}\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)\n",
            "requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/pmxcobwm/file_stream. args: ('https://api.wandb.ai/files/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/pmxcobwm/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 38, 'content': ['2020-05-11T09:03:21.067519 257/312 [=======================>......] - ETA: 40s - loss: 0.5086 - accuracy: 0.7549\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\r']}, 'wandb-events.jsonl': {'offset': 13, 'content': ['{\"system.gpu.0.gpu\": 18.2, \"system.gpu.0.memory\": 9.6, \"system.gpu.0.memoryAllocated\": 55.25, \"system.gpu.0.temp\": 72.53, \"system.gpu.0.powerWatts\": 90.17, \"system.gpu.0.powerPercent\": 36.07, \"system.cpu\": 52.93, \"system.memory\": 17.8, \"system.disk\": 52.1, \"system.proc.memory.availableMB\": 10707.54, \"system.proc.memory.rssMB\": 2725.42, \"system.proc.memory.percent\": 20.93, \"system.proc.cpu.threads\": 36.53, \"system.network.sent\": 64683729, \"system.network.recv\": 3622609, \"_wandb\": true, \"_timestamp\": 1589187796, \"_runtime\": 2495}\\n']}}}}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r313/312 [==============================] - 235s 750ms/step - loss: 0.5001 - accuracy: 0.7618 - val_loss: 0.5149 - val_accuracy: 0.7779\n",
            "Epoch 00001: val_loss improved from 0.64547 to 0.51495, saving model to /content/wandb/run-20200511_085614-pmxcobwm/model-best.h5\n",
            "Epoch 3/10\n",
            "  1/312 [..............................] - ETA: 42s - loss: 0.4338 - accuracy: 0.8000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "500 response executing GraphQL.\n",
            "{\"error\":\"Error 1040: Too many connections\"}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  2/312 [..............................] - ETA: 2:30 - loss: 0.4450 - accuracy: 0.8100"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "requests_with_retry encountered retryable exception: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/files/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/pmxcobwm/file_stream. args: ('https://api.wandb.ai/files/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/pmxcobwm/file_stream',), kwargs: {'json': {'files': {'output.log': {'offset': 38, 'content': ['2020-05-11T09:03:21.067519 257/312 [=======================>......] - ETA: 40s - loss: 0.5086 - accuracy: 0.7549\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\x08\\r']}, 'wandb-events.jsonl': {'offset': 13, 'content': ['{\"system.gpu.0.gpu\": 18.2, \"system.gpu.0.memory\": 9.6, \"system.gpu.0.memoryAllocated\": 55.25, \"system.gpu.0.temp\": 72.53, \"system.gpu.0.powerWatts\": 90.17, \"system.gpu.0.powerPercent\": 36.07, \"system.cpu\": 52.93, \"system.memory\": 17.8, \"system.disk\": 52.1, \"system.proc.memory.availableMB\": 10707.54, \"system.proc.memory.rssMB\": 2725.42, \"system.proc.memory.percent\": 20.93, \"system.proc.cpu.threads\": 36.53, \"system.network.sent\": 64683729, \"system.network.recv\": 3622609, \"_wandb\": true, \"_timestamp\": 1589187796, \"_runtime\": 2495}\\n']}}}}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r  3/312 [..............................] - ETA: 2:55 - loss: 0.4611 - accuracy: 0.7933"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "500 response executing GraphQL.\n",
            "{\"error\":\"Error 1040: Too many connections\"}\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  6/312 [..............................] - ETA: 3:20 - loss: 0.4672 - accuracy: 0.7900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "500 response executing GraphQL.\n",
            "{\"error\":\"Error 1040: Too many connections\"}\n",
            "\n",
            "Retry attempt failed:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/wandb/retry.py\", line 95, in __call__\n",
            "    result = self._call_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/wandb/apis/internal.py\", line 116, in execute\n",
            "    six.reraise(*sys.exc_info())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/wandb/apis/internal.py\", line 110, in execute\n",
            "    return self.client.execute(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gql/client.py\", line 52, in execute\n",
            "    result = self._get_result(document, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gql/client.py\", line 60, in _get_result\n",
            "    return self.transport.execute(document, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gql/transport/requests.py\", line 39, in execute\n",
            "    request.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/requests/models.py\", line 941, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 500 Server Error: Internal Server Error for url: https://api.wandb.ai/graphql\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (HTTPError), entering retry loop. See /content/wandb/debug.log for full traceback.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 13/312 [>.............................] - ETA: 3:28 - loss: 0.4789 - accuracy: 0.7769"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:08.717795, resuming normal operation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 20/312 [>.............................] - ETA: 3:30 - loss: 0.4651 - accuracy: 0.7900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:48.937839, resuming normal operation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/312 [==============================] - 234s 748ms/step - loss: 0.4211 - accuracy: 0.8212 - val_loss: 0.4592 - val_accuracy: 0.8037\n",
            "Epoch 00002: val_loss improved from 0.51495 to 0.45920, saving model to /content/wandb/run-20200511_085614-pmxcobwm/model-best.h5\n",
            "Epoch 4/10\n",
            "313/312 [==============================] - 227s 726ms/step - loss: 0.3760 - accuracy: 0.8507 - val_loss: 0.4142 - val_accuracy: 0.8156\n",
            "Epoch 00003: val_loss improved from 0.45920 to 0.41423, saving model to /content/wandb/run-20200511_085614-pmxcobwm/model-best.h5\n",
            "Epoch 5/10\n",
            "313/312 [==============================] - 227s 726ms/step - loss: 0.3394 - accuracy: 0.8712 - val_loss: 0.5066 - val_accuracy: 0.8182\n",
            "Epoch 6/10\n",
            "313/312 [==============================] - 228s 727ms/step - loss: 0.3087 - accuracy: 0.8883 - val_loss: 0.4202 - val_accuracy: 0.8161\n",
            "Epoch 7/10\n",
            "313/312 [==============================] - 234s 746ms/step - loss: 0.2788 - accuracy: 0.9097 - val_loss: 0.2937 - val_accuracy: 0.8368\n",
            "Epoch 00006: val_loss improved from 0.41423 to 0.29370, saving model to /content/wandb/run-20200511_085614-pmxcobwm/model-best.h5\n",
            "Epoch 8/10\n",
            "313/312 [==============================] - 234s 749ms/step - loss: 0.2591 - accuracy: 0.9151 - val_loss: 0.3945 - val_accuracy: 0.8213\n",
            "Epoch 9/10\n",
            "313/312 [==============================] - 235s 752ms/step - loss: 0.2397 - accuracy: 0.9250 - val_loss: 0.4001 - val_accuracy: 0.8223\n",
            "Epoch 10/10\n",
            "313/312 [==============================] - 236s 753ms/step - loss: 0.2250 - accuracy: 0.9293 - val_loss: 0.4341 - val_accuracy: 0.8280\n",
            "wandb: Agent Finished Run: pmxcobwm \n",
            "\n",
            "wandb: Agent Starting Run: noyzokjr with config:\n",
            "\tmodel_name: vgg16\n",
            "\tsamples: 100\n",
            "wandb: Agent Started Run: noyzokjr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/noyzokjr\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/noyzokjr</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: keras\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 64\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 10\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.0001\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: vgg16\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "samples:\n",
            "  desc: null\n",
            "  value: 100\n",
            "steps_per_epoch:\n",
            "  desc: null\n",
            "  value: 312.5\n",
            "\n",
            "Found 100 validated image filenames belonging to 2 classes.\n",
            "Found 2000 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "313/312 [==============================] - 230s 734ms/step - loss: 0.6804 - accuracy: 0.6080 - val_loss: 0.5487 - val_accuracy: 0.7611\n",
            "Epoch 00000: val_loss improved from inf to 0.54867, saving model to /content/wandb/run-20200511_093512-noyzokjr/model-best.h5\n",
            "Epoch 2/10\n",
            "313/312 [==============================] - 223s 714ms/step - loss: 0.5169 - accuracy: 0.7460 - val_loss: 0.4339 - val_accuracy: 0.8063\n",
            "Epoch 00001: val_loss improved from 0.54867 to 0.43387, saving model to /content/wandb/run-20200511_093512-noyzokjr/model-best.h5\n",
            "Epoch 3/10\n",
            "313/312 [==============================] - 220s 704ms/step - loss: 0.4451 - accuracy: 0.7999 - val_loss: 0.5055 - val_accuracy: 0.8399\n",
            "Epoch 4/10\n",
            "313/312 [==============================] - 216s 692ms/step - loss: 0.3983 - accuracy: 0.8305 - val_loss: 0.3628 - val_accuracy: 0.8357\n",
            "Epoch 00003: val_loss improved from 0.43387 to 0.36281, saving model to /content/wandb/run-20200511_093512-noyzokjr/model-best.h5\n",
            "Epoch 5/10\n",
            "313/312 [==============================] - 219s 700ms/step - loss: 0.3673 - accuracy: 0.8481 - val_loss: 0.3579 - val_accuracy: 0.8481\n",
            "Epoch 00004: val_loss improved from 0.36281 to 0.35787, saving model to /content/wandb/run-20200511_093512-noyzokjr/model-best.h5\n",
            "Epoch 6/10\n",
            "313/312 [==============================] - 221s 707ms/step - loss: 0.3412 - accuracy: 0.8637 - val_loss: 0.3835 - val_accuracy: 0.8559\n",
            "Epoch 7/10\n",
            "313/312 [==============================] - 224s 716ms/step - loss: 0.3188 - accuracy: 0.8744 - val_loss: 0.2087 - val_accuracy: 0.8574\n",
            "Epoch 00006: val_loss improved from 0.35787 to 0.20873, saving model to /content/wandb/run-20200511_093512-noyzokjr/model-best.h5\n",
            "Epoch 8/10\n",
            "313/312 [==============================] - 227s 724ms/step - loss: 0.2982 - accuracy: 0.8852 - val_loss: 0.3540 - val_accuracy: 0.8518\n",
            "Epoch 9/10\n",
            "313/312 [==============================] - 226s 721ms/step - loss: 0.2823 - accuracy: 0.8896 - val_loss: 0.3362 - val_accuracy: 0.8564\n",
            "Epoch 10/10\n",
            "313/312 [==============================] - 227s 726ms/step - loss: 0.2702 - accuracy: 0.8981 - val_loss: 0.2567 - val_accuracy: 0.8605\n",
            "wandb: Agent Finished Run: noyzokjr \n",
            "\n",
            "wandb: Agent Starting Run: 08ho2vat with config:\n",
            "\tmodel_name: vgg16\n",
            "\tsamples: 1000\n",
            "wandb: Agent Started Run: 08ho2vat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/08ho2vat\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/08ho2vat</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: keras\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 64\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 10\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.0001\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: vgg16\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "samples:\n",
            "  desc: null\n",
            "  value: 1000\n",
            "steps_per_epoch:\n",
            "  desc: null\n",
            "  value: 312.5\n",
            "\n",
            "Found 1000 validated image filenames belonging to 2 classes.\n",
            "Found 2000 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "313/312 [==============================] - 272s 868ms/step - loss: 0.6957 - accuracy: 0.5938 - val_loss: 0.4993 - val_accuracy: 0.8191\n",
            "Epoch 00000: val_loss improved from inf to 0.49930, saving model to /content/wandb/run-20200511_101235-08ho2vat/model-best.h5\n",
            "Epoch 2/10\n",
            "313/312 [==============================] - 265s 847ms/step - loss: 0.5430 - accuracy: 0.7209 - val_loss: 0.3545 - val_accuracy: 0.8445\n",
            "Epoch 00001: val_loss improved from 0.49930 to 0.35450, saving model to /content/wandb/run-20200511_101235-08ho2vat/model-best.h5\n",
            "Epoch 3/10\n",
            "313/312 [==============================] - 271s 866ms/step - loss: 0.4748 - accuracy: 0.7775 - val_loss: 0.3314 - val_accuracy: 0.8585\n",
            "Epoch 00002: val_loss improved from 0.35450 to 0.33137, saving model to /content/wandb/run-20200511_101235-08ho2vat/model-best.h5\n",
            "Epoch 4/10\n",
            "313/312 [==============================] - 277s 885ms/step - loss: 0.4390 - accuracy: 0.7992 - val_loss: 0.3228 - val_accuracy: 0.8683\n",
            "Epoch 00003: val_loss improved from 0.33137 to 0.32275, saving model to /content/wandb/run-20200511_101235-08ho2vat/model-best.h5\n",
            "Epoch 5/10\n",
            "313/312 [==============================] - 272s 868ms/step - loss: 0.4142 - accuracy: 0.8140 - val_loss: 0.3222 - val_accuracy: 0.8745\n",
            "Epoch 00004: val_loss improved from 0.32275 to 0.32216, saving model to /content/wandb/run-20200511_101235-08ho2vat/model-best.h5\n",
            "Epoch 6/10\n",
            "313/312 [==============================] - 277s 884ms/step - loss: 0.3944 - accuracy: 0.8297 - val_loss: 0.2704 - val_accuracy: 0.8719\n",
            "Epoch 00005: val_loss improved from 0.32216 to 0.27045, saving model to /content/wandb/run-20200511_101235-08ho2vat/model-best.h5\n",
            "Epoch 7/10\n",
            "313/312 [==============================] - 260s 830ms/step - loss: 0.3793 - accuracy: 0.8354 - val_loss: 0.3025 - val_accuracy: 0.8900\n",
            "Epoch 8/10\n",
            "313/312 [==============================] - 263s 840ms/step - loss: 0.3702 - accuracy: 0.8406 - val_loss: 0.2603 - val_accuracy: 0.8843\n",
            "Epoch 00007: val_loss improved from 0.27045 to 0.26030, saving model to /content/wandb/run-20200511_101235-08ho2vat/model-best.h5\n",
            "Epoch 9/10\n",
            "313/312 [==============================] - 254s 813ms/step - loss: 0.3563 - accuracy: 0.8468 - val_loss: 0.2223 - val_accuracy: 0.8931\n",
            "Epoch 00008: val_loss improved from 0.26030 to 0.22227, saving model to /content/wandb/run-20200511_101235-08ho2vat/model-best.h5\n",
            "Epoch 10/10\n",
            "313/312 [==============================] - 250s 800ms/step - loss: 0.3458 - accuracy: 0.8527 - val_loss: 0.3785 - val_accuracy: 0.8910\n",
            "wandb: Agent Finished Run: 08ho2vat \n",
            "\n",
            "wandb: Agent Starting Run: j9fp77sy with config:\n",
            "\tmodel_name: vgg16\n",
            "\tsamples: 20000\n",
            "wandb: Agent Started Run: j9fp77sy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/j9fp77sy\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/j9fp77sy</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: keras\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 64\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 10\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.0001\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: vgg16\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "samples:\n",
            "  desc: null\n",
            "  value: 20000\n",
            "steps_per_epoch:\n",
            "  desc: null\n",
            "  value: 312.5\n",
            "\n",
            "Found 20000 validated image filenames belonging to 2 classes.\n",
            "Found 2000 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "313/312 [==============================] - 262s 836ms/step - loss: 0.7059 - accuracy: 0.5814 - val_loss: 0.4602 - val_accuracy: 0.8206\n",
            "Epoch 00000: val_loss improved from inf to 0.46016, saving model to /content/wandb/run-20200511_105707-j9fp77sy/model-best.h5\n",
            "Epoch 2/10\n",
            "313/312 [==============================] - 253s 808ms/step - loss: 0.5485 - accuracy: 0.7161 - val_loss: 0.4267 - val_accuracy: 0.8528\n",
            "Epoch 00001: val_loss improved from 0.46016 to 0.42667, saving model to /content/wandb/run-20200511_105707-j9fp77sy/model-best.h5\n",
            "Epoch 3/10\n",
            "313/312 [==============================] - 252s 805ms/step - loss: 0.4864 - accuracy: 0.7646 - val_loss: 0.3573 - val_accuracy: 0.8673\n",
            "Epoch 00002: val_loss improved from 0.42667 to 0.35731, saving model to /content/wandb/run-20200511_105707-j9fp77sy/model-best.h5\n",
            "Epoch 4/10\n",
            "313/312 [==============================] - 253s 809ms/step - loss: 0.4457 - accuracy: 0.7937 - val_loss: 0.3326 - val_accuracy: 0.8714\n",
            "Epoch 00003: val_loss improved from 0.35731 to 0.33259, saving model to /content/wandb/run-20200511_105707-j9fp77sy/model-best.h5\n",
            "Epoch 5/10\n",
            "313/312 [==============================] - 251s 802ms/step - loss: 0.4216 - accuracy: 0.8077 - val_loss: 0.3222 - val_accuracy: 0.8812\n",
            "Epoch 00004: val_loss improved from 0.33259 to 0.32223, saving model to /content/wandb/run-20200511_105707-j9fp77sy/model-best.h5\n",
            "Epoch 6/10\n",
            "313/312 [==============================] - 264s 842ms/step - loss: 0.4057 - accuracy: 0.8161 - val_loss: 0.2711 - val_accuracy: 0.8833\n",
            "Epoch 00005: val_loss improved from 0.32223 to 0.27111, saving model to /content/wandb/run-20200511_105707-j9fp77sy/model-best.h5\n",
            "Epoch 7/10\n",
            "313/312 [==============================] - 261s 834ms/step - loss: 0.3918 - accuracy: 0.8260 - val_loss: 0.2981 - val_accuracy: 0.8889\n",
            "Epoch 8/10\n",
            "313/312 [==============================] - 259s 828ms/step - loss: 0.3775 - accuracy: 0.8318 - val_loss: 0.2882 - val_accuracy: 0.8843\n",
            "Epoch 9/10\n",
            "313/312 [==============================] - 256s 817ms/step - loss: 0.3712 - accuracy: 0.8343 - val_loss: 0.2581 - val_accuracy: 0.8920\n",
            "Epoch 00008: val_loss improved from 0.27111 to 0.25809, saving model to /content/wandb/run-20200511_105707-j9fp77sy/model-best.h5\n",
            "Epoch 10/10\n",
            "313/312 [==============================] - 263s 842ms/step - loss: 0.3588 - accuracy: 0.8422 - val_loss: 0.3174 - val_accuracy: 0.8895\n",
            "wandb: Agent Finished Run: j9fp77sy \n",
            "\n",
            "wandb: Agent Starting Run: n0gal6xf with config:\n",
            "\tmodel_name: resnext101\n",
            "\tsamples: 10\n",
            "wandb: Agent Started Run: n0gal6xf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/n0gal6xf\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/n0gal6xf</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: keras\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 64\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 10\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.0001\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: resnext101\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "samples:\n",
            "  desc: null\n",
            "  value: 10\n",
            "steps_per_epoch:\n",
            "  desc: null\n",
            "  value: 312.5\n",
            "\n",
            "Found 10 validated image filenames belonging to 2 classes.\n",
            "Found 2000 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "  2/312 [..............................] - ETA: 29:52 - loss: 1.5356 - accuracy: 0.5000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.223460). Check your callbacks.\n",
            "  % (hook_name, delta_t_median), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/312 [==============================] - 98s 312ms/step - loss: 0.1179 - accuracy: 0.9601 - val_loss: 0.7904 - val_accuracy: 0.5101\n",
            "Epoch 00000: val_loss improved from inf to 0.79039, saving model to /content/wandb/run-20200511_114010-n0gal6xf/model-best.h5\n",
            "Epoch 2/10\n",
            "313/312 [==============================] - 81s 258ms/step - loss: 0.0108 - accuracy: 0.9987 - val_loss: 0.7244 - val_accuracy: 0.5072\n",
            "Epoch 00001: val_loss improved from 0.79039 to 0.72436, saving model to /content/wandb/run-20200511_114010-n0gal6xf/model-best.h5\n",
            "Epoch 3/10\n",
            "313/312 [==============================] - 79s 253ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.7587 - val_accuracy: 0.5093\n",
            "Epoch 4/10\n",
            "313/312 [==============================] - 79s 253ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.7657 - val_accuracy: 0.5088\n",
            "Epoch 5/10\n",
            "313/312 [==============================] - 79s 253ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.8497 - val_accuracy: 0.5129\n",
            "Epoch 6/10\n",
            "313/312 [==============================] - 80s 255ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8813 - val_accuracy: 0.5093\n",
            "Epoch 7/10\n",
            "313/312 [==============================] - 80s 255ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.5098\n",
            "Epoch 8/10\n",
            "313/312 [==============================] - 80s 254ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8874 - val_accuracy: 0.4979\n",
            "Epoch 9/10\n",
            "313/312 [==============================] - 79s 252ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9408 - val_accuracy: 0.5077\n",
            "Epoch 10/10\n",
            "313/312 [==============================] - 79s 252ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.9252 - val_accuracy: 0.5186\n",
            "wandb: Agent Finished Run: n0gal6xf \n",
            "\n",
            "wandb: Agent Starting Run: 9kmu4tfz with config:\n",
            "\tmodel_name: resnext101\n",
            "\tsamples: 50\n",
            "wandb: Agent Started Run: 9kmu4tfz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep</a><br/>\n",
              "                Sweep page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x</a><br/>\n",
              "Run page: <a href=\"https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/9kmu4tfz\" target=\"_blank\">https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/runs/9kmu4tfz</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "wandb_version: 1\n",
            "\n",
            "_wandb:\n",
            "  desc: null\n",
            "  value:\n",
            "    cli_version: 0.8.35\n",
            "    framework: keras\n",
            "    is_jupyter_run: true\n",
            "    is_kaggle_kernel: false\n",
            "    python_version: 3.6.9\n",
            "batch_size:\n",
            "  desc: null\n",
            "  value: 64\n",
            "epochs:\n",
            "  desc: null\n",
            "  value: 10\n",
            "lr:\n",
            "  desc: null\n",
            "  value: 0.0001\n",
            "model_name:\n",
            "  desc: null\n",
            "  value: resnext101\n",
            "momentum:\n",
            "  desc: null\n",
            "  value: 0.9\n",
            "samples:\n",
            "  desc: null\n",
            "  value: 50\n",
            "steps_per_epoch:\n",
            "  desc: null\n",
            "  value: 312.5\n",
            "\n",
            "Found 50 validated image filenames belonging to 2 classes.\n",
            "Found 2000 validated image filenames belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "313/312 [==============================] - 283s 905ms/step - loss: 0.1956 - accuracy: 0.9236 - val_loss: 1.0163 - val_accuracy: 0.5101\n",
            "Epoch 00000: val_loss improved from inf to 1.01634, saving model to /content/wandb/run-20200511_115430-9kmu4tfz/model-best.h5\n",
            "Epoch 2/10\n",
            "313/312 [==============================] - 266s 850ms/step - loss: 0.0321 - accuracy: 0.9914 - val_loss: 1.0816 - val_accuracy: 0.5088\n",
            "Epoch 3/10\n",
            "313/312 [==============================] - 266s 849ms/step - loss: 0.0175 - accuracy: 0.9967 - val_loss: 1.3175 - val_accuracy: 0.5124\n",
            "Epoch 4/10\n",
            "313/312 [==============================] - 266s 848ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 1.1910 - val_accuracy: 0.5124\n",
            "Epoch 5/10\n",
            "313/312 [==============================] - 265s 848ms/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 1.1879 - val_accuracy: 0.5072\n",
            "Epoch 6/10\n",
            "269/312 [========================>.....] - ETA: 35s - loss: 0.0076 - accuracy: 0.9990"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiWLooCkeWJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_acc = [(i, max(result['val_accuracy'])) for i, result in zip(results_count, results)]\n",
        "acc = [(i, max(result['accuracy'])) for i, result in zip(results_count, results)]\n",
        "val_loss = [(i, min(result['val_loss'])) for i, result in zip(results_count, results)]\n",
        "loss = [(i, min(result['loss'])) for i, result in zip(results_count, results)]\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(*zip(*val_acc), '-o', label='val_acc')\n",
        "plt.plot(*zip(*acc), '-o', label='acc')\n",
        "plt.plot(*zip(*val_loss), '-o', label='val_loss')\n",
        "plt.plot(*zip(*loss), '-o', label='loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSf-uTFHLUwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-mIziGjfHJO",
        "colab_type": "text"
      },
      "source": [
        "https://app.wandb.ai/grachev/Copy_20of_20How_much_samples_is_enough_for_transfer_learning_same_steps_per_epoch_sweep/sweeps/djxmo76x/table?workspace=user-grachev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCCNVuspLzb6",
        "colab_type": "text"
      },
      "source": [
        "**500 samples is ok for binary classification**"
      ]
    }
  ]
}