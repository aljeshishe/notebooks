{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template_vgg_gpu_v2_with_wb.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aljeshishe/notebooks/blob/master/template_vgg_gpu_v2_with_wb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYN4BJRj04iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import sys \n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten \n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from time import time "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKmeruBkZna8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "# use gpu/cpu/tpu\n",
        "# see details in https://colab.research.google.com/drive/1cpuwjKTJbMjlvZ7opyrWzMXF_NYnjkiE#scrollTo=y3gk7nSvTUFZ\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "COLAB_TPU_ADDR = os.environ.get('COLAB_TPU_ADDR')\n",
        "if COLAB_TPU_ADDR:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + COLAB_TPU_ADDR)\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  # This is the TPU initialization code that has to be at the beginning.\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "  print('Running on TPU ')  \n",
        "elif len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypW8-j30ulfo",
        "colab_type": "code",
        "outputId": "48b9200f-b5dd-472a-da41-bfcd04afe0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def notebook_name():\n",
        "  import re\n",
        "  import ipykernel\n",
        "  import requests\n",
        "\n",
        "  from notebook.notebookapp import list_running_servers\n",
        "  # kernel_id = re.search('kernel-(.*).json', ipykernel.connect.get_connection_file()).group(1)\n",
        "  for ss in list_running_servers():\n",
        "      response = requests.get(f'{ss[\"url\"]}api/sessions',params={'token': ss.get('token', '')})\n",
        "      return response.json()[0]['name']\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import os\n",
        "project, _, _ = notebook_name().rpartition('.')\n",
        "working_dir = f'/content/drive/My Drive/Colab Notebooks/{project}'\n",
        "print(f'Current project: {project}')\n",
        "print(f'Places at: {working_dir}')\n",
        "pathlib.Path(working_dir).mkdir(parents=True, exist_ok=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current project: template_vgg_gpu_v2_with_wb\n",
            "Places at: /content/drive/My Drive/Colab Notebooks/template_vgg_gpu_v2_with_wb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiD_iLrWBaGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install wandb -q"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJZjYfD0_rFO",
        "colab_type": "code",
        "outputId": "d321be51-8a45-4667-93c3-d7a4a7f66719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#load dataset\n",
        "(trainX, trainY),(testX, testY) = cifar10.load_data()\n",
        "\n",
        "#one hot encode the target \n",
        "trainY = keras.utils.to_categorical(trainY)\n",
        "testY = keras.utils.to_categorical(testY)\n",
        "\n",
        "# normalize the data\n",
        "trainX = trainX.astype('float32') / 255.0\n",
        "testX = testX.astype('float32') / 255.0\n",
        "\n",
        "v_split = 0.5\n",
        "index_of_validation = int(v_split * len(testX))\n",
        "validX = np.asarray(testX[-index_of_validation:])\n",
        "validY = np.asarray(testY[-index_of_validation:])\n",
        "testX = np.asarray(testX[:-index_of_validation])\n",
        "testY = np.asarray(testY[:-index_of_validation])\n",
        "print(f'Prepared dataset:')\n",
        "print(f'trainX:{trainX.shape}')\n",
        "print(f'trainY:{trainY.shape}')\n",
        "print(f'validX:{validX.shape}')\n",
        "print(f'validY:{validY.shape}')\n",
        "print(f'testX:{testX.shape}')\n",
        "print(f'testY:{testY.shape}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prepared dataset:\n",
            "trainX:(50000, 32, 32, 3)\n",
            "trainY:(50000, 10)\n",
            "validX:(5000, 32, 32, 3)\n",
            "validY:(5000, 10)\n",
            "testX:(5000, 32, 32, 3)\n",
            "testY:(5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke6le2McoCpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "config = dict(\n",
        "  batch_size = 64,          # input batch size for training (default: 64)\n",
        "  epochs = 1000,             # number of epochs to train (default: 10)\n",
        "  lr = 0.001,               # learning rate (default: 0.01)\n",
        "  momentum = 0.9,          # SGD momentum (default: 0.5) \n",
        "  seed = 42,               # random seed (default: 42)\n",
        "  log_interval = 10,     # how many batches to wait before logging training status\n",
        "  weight_decay = 0.0005\n",
        ")\n",
        "wandb.init(project=project, dir=working_dir, config=config)\n",
        "config = wandb.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--8PDw7LAq8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg():\n",
        "  input_shape = (trainX.shape[1], trainX.shape[2], 3)\n",
        "  \n",
        "  # Define the model architecture - This is a simplified version of the VGG19 architecture\n",
        "  model = Sequential()\n",
        "  \n",
        "  # Set of Conv2D, Conv2D, MaxPooling2D layers with 32 and 64 filters\n",
        "  model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # Another set of Conv2D, Conv2D, MaxPooling2D layers with 128 filters\n",
        "  model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(filters = 128, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # Another set of Conv2D, Conv2D, MaxPooling2D layers with 256 filters\n",
        "  model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(filters = 256, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # Another set of Conv2D, Conv2D, MaxPooling2D layers with 512 filters\n",
        "  model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(filters = 512, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # Another set of Conv2D, Conv2D, MaxPooling2D layers with 512 filters\n",
        "  model.add(Conv2D(filters = 1024, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Conv2D(filters = 1024, kernel_size = (3, 3), padding = 'same', \n",
        "                    activation ='relu', input_shape = input_shape, kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  # Flatten\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, activation ='relu', kernel_regularizer=regularizers.l2(config.weight_decay)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "  num_classes = 10\n",
        "  model.add(Dense(num_classes, activation = \"softmax\"))\n",
        "  opt = SGD(lr = config.lr, momentum=config.momentum)\n",
        "  model.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYxyiIGoPQ3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define model\n",
        "def baseline():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32,32,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Conv2D(128,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "    model.add(Dropout(0.4))\n",
        "   \n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation = 'softmax'))\n",
        "    \n",
        "    #compile model \n",
        "    opt = SGD(lr = config.lr, momentum=config.momentum)\n",
        "    model.compile(optimizer=opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwhpW4_UPRlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = baseline()\n",
        "\n",
        "#create data generator \n",
        "datagen = ImageDataGenerator(width_shift_range = 0.1, height_shift_range = 0.1, horizontal_flip = True)\n",
        "\n",
        "#iterator \n",
        "train = datagen.flow(trainX, trainY, batch_size=config.batch_size)\n",
        "\n",
        "# fit model\n",
        "steps = int(trainX.shape[0]/ 64)\n",
        "history = model.fit_generator(train,\n",
        "                              steps_per_epoch=steps,\n",
        "                              epochs=config.epochs, validation_data=(validX, validY), verbose=1,\n",
        "                              callbacks=[WandbCallback(validation_data=(validX, validY),\n",
        "                                                       save_model=True, verbose=1)])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu1IeC6g_Btz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# restore a model file from a specific run by user \"vanpelt\" in \"my-project\"\n",
        "best_model = wandb.restore('model-best.h5')\n",
        "model.load_weights(best_model.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iRJXeDq_cI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfHX5GRi1a7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wandb.save(\"mymodel.h5\")\n",
        "model.save(os.path.join(wandb.run.dir, \"mymodel.h5\"))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}